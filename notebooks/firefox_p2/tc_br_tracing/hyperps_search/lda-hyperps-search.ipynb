{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction - Hyperparameters Search\n",
    "\n",
    "In this notebook we demonstrate the use of **LDA (Latent Dirichlet Allocation)** generative statistical model for Information Retrieval technique to make trace link recovery between Test Cases and Bug Reports.\n",
    "\n",
    "We model our study as follows:\n",
    "\n",
    "* Each bug report title, summary and description compose a single query.\n",
    "* We use each test case content as an entire document that must be returned to the query made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod_finder_util import mod_finder_util\n",
    "mod_finder_util.add_modules_origin_search_path()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from modules.utils import plots\n",
    "from modules.utils import firefox_dataset_p2 as fd\n",
    "from modules.utils import tokenizers as tok\n",
    "from modules.utils import aux_functions\n",
    "from modules.utils import model_evaluator as m_eval\n",
    "\n",
    "from modules.models.lda import LDA\n",
    "from modules.models.model_hyperps import LDA_Model_Hyperp\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCases.shape: (207, 12)\n",
      "BugReports.shape: (93, 19)\n",
      "Oracle.shape: (207, 93)\n"
     ]
    }
   ],
   "source": [
    "test_cases_df = fd.Datasets.read_testcases_df()\n",
    "bug_reports_df = fd.Datasets.read_selected_bug_reports_2_df()\n",
    "\n",
    "corpus = test_cases_df.tc_desc\n",
    "query = bug_reports_df.br_desc\n",
    "\n",
    "test_cases_names = test_cases_df.tc_name\n",
    "bug_reports_names = bug_reports_df.br_name\n",
    "\n",
    "orc = fd.Tc_BR_Oracles.read_oracle_expert_volunteers_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCases Subset Shape: (14, 10)\n",
      "BugReports Subset Shape: (15, 12)\n",
      "Oracle Subset Shape: (14, 15)\n"
     ]
    }
   ],
   "source": [
    "bugreports_subset_df = bug_reports_df[(bug_reports_df.Version == '48 Branch') | (bug_reports_df.Version == '60 Branch')].sample(15, random_state=42)\n",
    "testcases_subset_df = test_cases_df[(test_cases_df.TestDay.str.contains('20161014')) | (test_cases_df.TestDay.str.contains('20161028'))].sample(10, random_state=1000)\n",
    "\n",
    "selected_testcases = ['TC_{}_TRG'.format(tc_num) for tc_num in [13, 14, 15, 16, 17, 18]]  # should link with 48 Branch\n",
    "aux_tc = test_cases_df[test_cases_df.tc_name.isin(selected_testcases)]\n",
    "\n",
    "tc_subset_df = testcases_subset_df.append(aux_tc)\n",
    "tc_subset_df.drop_duplicates(inplace=True)\n",
    "\n",
    "corpus_subset = tc_subset_df.tc_desc\n",
    "query_subset = bugreports_subset_df.br_desc\n",
    "testcases_names_subset = tc_subset_df.tc_name\n",
    "bug_reports_names_subset = bugreports_subset_df.br_name\n",
    "orc_subset_df = orc.loc[testcases_names_subset, bug_reports_names_subset]\n",
    "\n",
    "print('TestCases Subset Shape: {}'.format(tc_subset_df.shape))\n",
    "print('BugReports Subset Shape: {}'.format(bugreports_subset_df.shape))\n",
    "print('Oracle Subset Shape: {}'.format(orc_subset_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model hyperparameters search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "all_hyperparams = {\n",
    "    LDA_Model_Hyperp.TOP.value : [3,5],\n",
    "    LDA_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('cosine',.75), ('cosine',.85), ('cosine',.95)] +\n",
    "                                                         [('jsd', .75), ('jsd', .85), ('jsd', .95)],\n",
    "    LDA_Model_Hyperp.LDA_MODEL_N_COMPONENTS.value: [5,10,20],\n",
    "    LDA_Model_Hyperp.LDA_MODEL_RANDOM_STATE.value : [2],\n",
    "    LDA_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1), (1,2)],\n",
    "    LDA_Model_Hyperp.VECTORIZER.value : [TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True), \n",
    "                         CountVectorizer(stop_words='english')],\n",
    "    LDA_Model_Hyperp.VECTORIZER_TOKENIZER.value : [tok.PorterStemmerBased_Tokenizer(), tok.LancasterStemmerBased_Tokenizer(), \n",
    "                                                   tok.WordNetBased_LemmaTokenizer(), tok.SnowballStemmerBased_Tokenizer()]    \n",
    "}\n",
    "\n",
    "hyperparams = aux_functions.generate_params_comb_list(**all_hyperparams)\n",
    "\n",
    "print('Performing model hyperparameters search...')\n",
    "\n",
    "def run_model(idx, **hyperp):    \n",
    "    current_model = LDA(**hyperp)\n",
    "    current_model.set_name('LDA_Model_{}'.format(idx))\n",
    "    current_model.recover_links(corpus_subset, query_subset, testcases_names_subset, bug_reports_names_subset)\n",
    "    \n",
    "    evaluator = m_eval.ModelEvaluator(orc_subset_df, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    evaluator.dump_model()\n",
    "    evaluator.dump_evaluator()\n",
    "        \n",
    "    return([evaluator.get_mean_precision(), \n",
    "            evaluator.get_mean_recall(),\n",
    "            evaluator.get_mean_fscore(), \n",
    "            evaluator.get_model().get_name(),\n",
    "            evaluator.get_model().get_top_value(),\n",
    "            evaluator.get_model().get_vectorizer_type(), \n",
    "            evaluator.get_model().get_sim_measure_min_threshold()[0],\n",
    "            evaluator.get_model().get_sim_measure_min_threshold()[1],\n",
    "            evaluator.get_model().get_model_dump_path(),\n",
    "            evaluator.get_evaluator_dump_path()\n",
    "           ])\n",
    "\n",
    "tasks = [(idx,hp) for idx,hp in enumerate(hyperparams)]\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(run_model)(idx, **hp) for idx,hp in tasks)\n",
    "results_df = pd.DataFrame(data=results, \n",
    "                          columns=['precision', 'recall', 'fscore', 'model_name', 'top_value', 'vectorizer', 'metric', 'metric_value', 'model_dump', 'evaluator_dump'])\n",
    "results_df = results_df.astype(dtype={'model_dump' : str, 'evaluator_dump' : str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Report -------------------\n",
      "\n",
      "Total of Analyzed Hyperparameters Combinations: 576\n",
      "\n",
      "Best Model Hyperparameters Combination Found:\n",
      "\n",
      "{'Measures': {'Mean FScore of LDA_Model_290': 0.2222222222222222,\n",
      "              'Mean Precision of LDA_Model_290': 0.26666666666666666,\n",
      "              'Mean Recall of LDA_Model_290': 0.1904761904761905},\n",
      " 'Setup': [{'Name': 'LDA_Model_290'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('cosine', 0.75)},\n",
      "           {'Top Value': 5},\n",
      "           {'LDA Model': {'batch_size': 128,\n",
      "                          'doc_topic_prior': None,\n",
      "                          'evaluate_every': -1,\n",
      "                          'learning_decay': 0.7,\n",
      "                          'learning_method': 'batch',\n",
      "                          'learning_offset': 10.0,\n",
      "                          'max_doc_update_iter': 100,\n",
      "                          'max_iter': 10,\n",
      "                          'mean_change_tol': 0.001,\n",
      "                          'n_components': 5,\n",
      "                          'n_jobs': -1,\n",
      "                          'n_topics': None,\n",
      "                          'perp_tol': 0.1,\n",
      "                          'random_state': 2,\n",
      "                          'topic_word_prior': None,\n",
      "                          'total_samples': 1000000.0,\n",
      "                          'verbose': 0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.float64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <utils.tokenizers.WordNetBased_LemmaTokenizer object at 0x7f29646d4da0>,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n"
     ]
    }
   ],
   "source": [
    "best_model = aux_functions.report_best_model(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_sim_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model for TOP 3 and 5 - Cosine 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Measures': {'Mean FScore of LDA_Model_2': 0.16,\n",
      "              'Mean Precision of LDA_Model_2': 0.26666666666666666,\n",
      "              'Mean Recall of LDA_Model_2': 0.11428571428571428},\n",
      " 'Setup': [{'Name': 'LDA_Model_2'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('cosine', 0.75)},\n",
      "           {'Top Value': 3},\n",
      "           {'LDA Model': {'batch_size': 128,\n",
      "                          'doc_topic_prior': None,\n",
      "                          'evaluate_every': -1,\n",
      "                          'learning_decay': 0.7,\n",
      "                          'learning_method': 'batch',\n",
      "                          'learning_offset': 10.0,\n",
      "                          'max_doc_update_iter': 100,\n",
      "                          'max_iter': 10,\n",
      "                          'mean_change_tol': 0.001,\n",
      "                          'n_components': 5,\n",
      "                          'n_jobs': -1,\n",
      "                          'n_topics': None,\n",
      "                          'perp_tol': 0.1,\n",
      "                          'random_state': 2,\n",
      "                          'topic_word_prior': None,\n",
      "                          'total_samples': 1000000.0,\n",
      "                          'verbose': 0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.float64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <utils.tokenizers.WordNetBased_LemmaTokenizer object at 0x7f2969673320>,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n",
      "------------------------------------------------------------------\n",
      "{'Measures': {'Mean FScore of LDA_Model_290': 0.2222222222222222,\n",
      "              'Mean Precision of LDA_Model_290': 0.26666666666666666,\n",
      "              'Mean Recall of LDA_Model_290': 0.1904761904761905},\n",
      " 'Setup': [{'Name': 'LDA_Model_290'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('cosine', 0.75)},\n",
      "           {'Top Value': 5},\n",
      "           {'LDA Model': {'batch_size': 128,\n",
      "                          'doc_topic_prior': None,\n",
      "                          'evaluate_every': -1,\n",
      "                          'learning_decay': 0.7,\n",
      "                          'learning_method': 'batch',\n",
      "                          'learning_offset': 10.0,\n",
      "                          'max_doc_update_iter': 100,\n",
      "                          'max_iter': 10,\n",
      "                          'mean_change_tol': 0.001,\n",
      "                          'n_components': 5,\n",
      "                          'n_jobs': -1,\n",
      "                          'n_topics': None,\n",
      "                          'perp_tol': 0.1,\n",
      "                          'random_state': 2,\n",
      "                          'topic_word_prior': None,\n",
      "                          'total_samples': 1000000.0,\n",
      "                          'verbose': 0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.float64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <utils.tokenizers.WordNetBased_LemmaTokenizer object at 0x7f2969662e48>,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aux_functions.print_report_top_3_and_5_v2(results_df, 0.75, 'cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model for TOP 3 and 5 - JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Measures': {'Mean FScore of LDA_Model_144': 0.0,\n",
      "              'Mean Precision of LDA_Model_144': 0.0,\n",
      "              'Mean Recall of LDA_Model_144': 0.0},\n",
      " 'Setup': [{'Name': 'LDA_Model_144'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('jsd', 0.75)},\n",
      "           {'Top Value': 3},\n",
      "           {'LDA Model': {'batch_size': 128,\n",
      "                          'doc_topic_prior': None,\n",
      "                          'evaluate_every': -1,\n",
      "                          'learning_decay': 0.7,\n",
      "                          'learning_method': 'batch',\n",
      "                          'learning_offset': 10.0,\n",
      "                          'max_doc_update_iter': 100,\n",
      "                          'max_iter': 10,\n",
      "                          'mean_change_tol': 0.001,\n",
      "                          'n_components': 5,\n",
      "                          'n_jobs': -1,\n",
      "                          'n_topics': None,\n",
      "                          'perp_tol': 0.1,\n",
      "                          'random_state': 2,\n",
      "                          'topic_word_prior': None,\n",
      "                          'total_samples': 1000000.0,\n",
      "                          'verbose': 0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.float64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <utils.tokenizers.PorterStemmerBased_Tokenizer object at 0x7f2969677978>,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n",
      "------------------------------------------------------------------\n",
      "{'Measures': {'Mean FScore of LDA_Model_432': 0.0,\n",
      "              'Mean Precision of LDA_Model_432': 0.0,\n",
      "              'Mean Recall of LDA_Model_432': 0.0},\n",
      " 'Setup': [{'Name': 'LDA_Model_432'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('jsd', 0.75)},\n",
      "           {'Top Value': 5},\n",
      "           {'LDA Model': {'batch_size': 128,\n",
      "                          'doc_topic_prior': None,\n",
      "                          'evaluate_every': -1,\n",
      "                          'learning_decay': 0.7,\n",
      "                          'learning_method': 'batch',\n",
      "                          'learning_offset': 10.0,\n",
      "                          'max_doc_update_iter': 100,\n",
      "                          'max_iter': 10,\n",
      "                          'mean_change_tol': 0.001,\n",
      "                          'n_components': 5,\n",
      "                          'n_jobs': -1,\n",
      "                          'n_topics': None,\n",
      "                          'perp_tol': 0.1,\n",
      "                          'random_state': 2,\n",
      "                          'topic_word_prior': None,\n",
      "                          'total_samples': 1000000.0,\n",
      "                          'verbose': 0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.float64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 1),\n",
      "                           'norm': 'l2',\n",
      "                           'preprocessor': None,\n",
      "                           'smooth_idf': True,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'sublinear_tf': False,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <utils.tokenizers.PorterStemmerBased_Tokenizer object at 0x7f29696775c0>,\n",
      "                           'use_idf': True,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>}]}\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aux_functions.print_report_top_3_and_5_v2(results_df, 0.75, 'jsd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction - Best Hyperparameters Search\n",
    "\n",
    "In this notebook we demonstrate the use of **LSI (Latent Semantic Indexing)** technique of Information Retrieval context to make trace link recovery between Test Cases and Bug Reports.\n",
    "\n",
    "We model our study as follows:\n",
    "\n",
    "* Each bug report title, summary and description compose a single query.\n",
    "* We use each use case content as an entire document that must be returned to the query made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod_finder_util import mod_finder_util\n",
    "mod_finder_util.add_modules_origin_search_path()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from modules.utils import plots\n",
    "from modules.utils import firefox_dataset_p2 as fd\n",
    "from modules.utils import tokenizers as tok\n",
    "from modules.utils import aux_functions\n",
    "from modules.utils import model_evaluator as m_eval\n",
    "\n",
    "from modules.models.lsi import LSI\n",
    "from modules.models.lsi import SimilarityMeasure\n",
    "from modules.models.model_hyperps import LSI_Model_Hyperp\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCases.shape: (207, 12)\n",
      "BugReports.shape: (93, 19)\n",
      "Oracle.shape: (207, 93)\n"
     ]
    }
   ],
   "source": [
    "test_cases_df = fd.Datasets.read_testcases_df()\n",
    "bug_reports_df = fd.Datasets.read_selected_bug_reports_2_df()\n",
    "\n",
    "corpus = test_cases_df.tc_desc\n",
    "query = bug_reports_df.br_desc\n",
    "\n",
    "test_cases_names = test_cases_df.tc_name\n",
    "bug_reports_names = bug_reports_df.br_name\n",
    "\n",
    "orc = fd.Tc_BR_Oracles.read_oracle_expert_volunteers_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCases Subset Shape: (14, 10)\n",
      "BugReports Subset Shape: (15, 12)\n",
      "Oracle Subset Shape: (14, 15)\n"
     ]
    }
   ],
   "source": [
    "bugreports_subset_df = bug_reports_df[(bug_reports_df.Version == '48 Branch') | (bug_reports_df.Version == '60 Branch')].sample(15, random_state=42)\n",
    "testcases_subset_df = test_cases_df[(test_cases_df.TestDay.str.contains('20161014')) | (test_cases_df.TestDay.str.contains('20161028'))].sample(10, random_state=1000)\n",
    "\n",
    "selected_testcases = ['TC_{}_TRG'.format(tc_num) for tc_num in [13, 14, 15, 16, 17, 18]]  # should link with 48 Branch\n",
    "aux_tc = test_cases_df[test_cases_df.tc_name.isin(selected_testcases)]\n",
    "\n",
    "tc_subset_df = testcases_subset_df.append(aux_tc)\n",
    "tc_subset_df.drop_duplicates(inplace=True)\n",
    "\n",
    "corpus_subset = tc_subset_df.tc_desc\n",
    "query_subset = bugreports_subset_df.br_desc\n",
    "testcases_names_subset = tc_subset_df.tc_name\n",
    "bug_reports_names_subset = bugreports_subset_df.br_name\n",
    "orc_subset_df = orc.loc[testcases_names_subset, bug_reports_names_subset]\n",
    "\n",
    "print('TestCases Subset Shape: {}'.format(tc_subset_df.shape))\n",
    "print('BugReports Subset Shape: {}'.format(bugreports_subset_df.shape))\n",
    "print('Oracle Subset Shape: {}'.format(orc_subset_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model hyperparameters search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Report -------------------\n",
      "\n",
      "Total of Analyzed Hyperparameters Combinations: 96\n",
      "\n",
      "Best Model Hyperparameters Combination Found:\n",
      "\n",
      "{'Measures': {'Mean FScore of LSI_Model_14': 0.21424501424501421,\n",
      "              'Mean Precision of LSI_Model_14': 0.26666666666666666,\n",
      "              'Mean Recall of LSI_Model_14': 0.1904761904761905},\n",
      " 'Setup': [{'Name': 'LSI_Model_14'},\n",
      "           {'Similarity Measure and Minimum Threshold': ('cosine', 0.75)},\n",
      "           {'Top Value': 10},\n",
      "           {'SVD Model': {'algorithm': 'randomized',\n",
      "                          'n_components': 5,\n",
      "                          'n_iter': 10,\n",
      "                          'random_state': 42,\n",
      "                          'tol': 0.0}},\n",
      "           {'Vectorizer': {'analyzer': 'word',\n",
      "                           'binary': False,\n",
      "                           'decode_error': 'strict',\n",
      "                           'dtype': <class 'numpy.int64'>,\n",
      "                           'encoding': 'utf-8',\n",
      "                           'input': 'content',\n",
      "                           'lowercase': True,\n",
      "                           'max_df': 1.0,\n",
      "                           'max_features': None,\n",
      "                           'min_df': 1,\n",
      "                           'ngram_range': (1, 2),\n",
      "                           'preprocessor': None,\n",
      "                           'stop_words': 'english',\n",
      "                           'strip_accents': None,\n",
      "                           'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                           'tokenizer': <utils.tokenizers.WordNetBased_LemmaTokenizer object at 0x7eff33d4a390>,\n",
      "                           'vocabulary': None}},\n",
      "           {'Vectorizer Type': <class 'sklearn.feature_extraction.text.CountVectorizer'>}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:    7.9s finished\n"
     ]
    }
   ],
   "source": [
    "all_hyperparams = {\n",
    "    LSI_Model_Hyperp.SIM_MEASURE_MIN_THRESHOLD.value : [('cosine' ,x)  for x in [.75,.85,.95]],\n",
    "    LSI_Model_Hyperp.TOP.value : [10],\n",
    "    LSI_Model_Hyperp.SVD_MODEL_N_COMPONENTS.value: [5,10],\n",
    "    LSI_Model_Hyperp.VECTORIZER_NGRAM_RANGE.value: [(1,1), (1,2)],\n",
    "    LSI_Model_Hyperp.VECTORIZER.value : [TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True), \n",
    "                         CountVectorizer(stop_words='english')],\n",
    "    LSI_Model_Hyperp.VECTORIZER_TOKENIZER.value : [tok.PorterStemmerBased_Tokenizer(), tok.LancasterStemmerBased_Tokenizer(), \n",
    "                                                   tok.WordNetBased_LemmaTokenizer(), tok.SnowballStemmerBased_Tokenizer()]\n",
    "}\n",
    "\n",
    "hyperparams = aux_functions.generate_params_comb_list(**all_hyperparams)          \n",
    "\n",
    "print('Performing model hyperparameters search...')\n",
    "\n",
    "def run_model(idx, **hyperp):    \n",
    "    current_model = LSI(**hyperp)\n",
    "    current_model.set_name('LSI_Model_{}'.format(idx))\n",
    "    current_model.recover_links(corpus_subset, query_subset, testcases_names_subset, bug_reports_names_subset)\n",
    "    \n",
    "    evaluator = m_eval.ModelEvaluator(orc_subset_df, current_model)\n",
    "    evaluator.evaluate_model()\n",
    "    evaluator.dump_model()\n",
    "    evaluator.dump_evaluator()\n",
    "    \n",
    "    return([evaluator.get_mean_precision(), \n",
    "            evaluator.get_mean_recall(),\n",
    "            evaluator.get_mean_fscore(), \n",
    "            evaluator.get_model().get_name(),\n",
    "            evaluator.get_model().get_top_value(),\n",
    "            evaluator.get_model().get_vectorizer_type(), \n",
    "            evaluator.get_model().get_tokenizer_type(),\n",
    "            evaluator.get_model().get_sim_measure_min_threshold()[0],\n",
    "            evaluator.get_model().get_sim_measure_min_threshold()[1],\n",
    "            evaluator.get_model().get_model_dump_path(),\n",
    "            evaluator.get_evaluator_dump_path()\n",
    "           ])\n",
    "\n",
    "tasks = [(idx,hp) for idx,hp in enumerate(hyperparams)]\n",
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(run_model)(idx, **hp) for idx,hp in tasks)\n",
    "#results = [run_model(t[0],**t[1]) for t in tasks]\n",
    "results_df = pd.DataFrame(data=results, \n",
    "                          columns=['precision', 'recall', 'fscore', 'model_name', 'top_value', 'vectorizer', 'tokenizer', 'metric', 'metric_value', 'model_dump', 'evaluator_dump'])\n",
    "results_df = results_df.astype(dtype={'model_dump' : str, 'evaluator_dump' : str})\n",
    "\n",
    "bm = aux_functions.report_best_model(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.save_sim_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model for TOP 3 and 5 - Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7394496e1523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maux_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_report_top_3_and_5_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimilarityMeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOSINE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/notebooks/firefox/utils/aux_functions.py\u001b[0m in \u001b[0;36mprint_report_top_3_and_5_v3\u001b[0;34m(results_df, metric)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_report_top_3_and_5_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mrow_idx_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mbm_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_dump'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_idx_top\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mevalu_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'evaluator_dump'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_idx_top\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m     55\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarning_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Since we are using Substitution to create the required docstring,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m         \"\"\"\n\u001b[1;32m   1784\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_argmax_with_skipna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trace-link-recovery-study/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanargmax\u001b[0;34m(values, axis, skipna)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \"\"\"\n\u001b[1;32m    525\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_arg_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "aux_functions.print_report_top_3_and_5_v3(results_df, SimilarityMeasure.COSINE.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
